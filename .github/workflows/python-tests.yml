name: Python Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

# Add permissions needed for the GitHub Pages Deploy Action
permissions:
  contents: write

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        pip install pytest pytest-cov pytest-json-report
    
    - name: Run unit tests
      run: |
        mkdir -p test-results/python
        # Use pytest-json to generate detailed test information
        # Continue even if tests fail
        set +e
        python -m pytest tests/unit -v --json-report --json-report-file=test-results/python/unit-results.json
        unit_test_exit=$?
        set -e
        
        # Extract test counts from the JSON results file
        echo "UNIT_TOTAL=$(python -c "import json; data = json.load(open('test-results/python/unit-results.json')); print(data['summary']['total'])")" >> $GITHUB_ENV
        echo "UNIT_PASSED=$(python -c "import json; data = json.load(open('test-results/python/unit-results.json')); print(data['summary']['passed'])")" >> $GITHUB_ENV
        echo "UNIT_TEST_EXIT=$unit_test_exit" >> $GITHUB_ENV
    
    - name: Run integration tests
      if: always()
      run: |
        # Use pytest-json to generate detailed test information
        # Continue even if tests fail
        set +e
        python -m pytest tests/integration -v --json-report --json-report-file=test-results/python/integration-results.json
        integration_test_exit=$?
        set -e
        
        # Extract test counts from the JSON results file
        echo "INTEGRATION_TOTAL=$(python -c "import json; data = json.load(open('test-results/python/integration-results.json')); print(data['summary']['total'])")" >> $GITHUB_ENV
        echo "INTEGRATION_PASSED=$(python -c "import json; data = json.load(open('test-results/python/integration-results.json')); print(data['summary']['passed'])")" >> $GITHUB_ENV
        echo "INTEGRATION_TEST_EXIT=$integration_test_exit" >> $GITHUB_ENV
    
    - name: Run coverage report
      if: always()
      run: |
        mkdir -p test-results/python/coverage
        # Try to run coverage, but don't fail if tests fail
        set +e
        pytest --cov=. --cov-report=xml --cov-report=term-missing --cov-report=html:test-results/python/coverage
        cov_exit_code=$?
        set -e
        
        # Extract coverage percentage if the file exists
        if [ -f "coverage.xml" ]; then
          echo "COVERAGE_PCT=$(python -c "import xml.etree.ElementTree as ET; tree = ET.parse('coverage.xml'); root = tree.getroot(); print(round(float(root.attrib['line-rate']) * 100))")" >> $GITHUB_ENV
        else
          echo "COVERAGE_PCT=0" >> $GITHUB_ENV
          # Create a placeholder coverage report
          echo '<html><body><h1>No Coverage Report Available</h1><p>Tests failed to run properly.</p></body></html>' > test-results/python/coverage/index.html
        fi
    
    - name: Generate test stats badge
      if: always()
      run: |
        mkdir -p test-results/python
        
        # Set defaults if tests failed
        if [ -z "$UNIT_TOTAL" ]; then
          echo "UNIT_TOTAL=0" >> $GITHUB_ENV
        fi
        
        if [ -z "$UNIT_PASSED" ]; then
          echo "UNIT_PASSED=0" >> $GITHUB_ENV
        fi
        
        if [ -z "$INTEGRATION_TOTAL" ]; then
          echo "INTEGRATION_TOTAL=0" >> $GITHUB_ENV
        fi
        
        if [ -z "$INTEGRATION_PASSED" ]; then
          echo "INTEGRATION_PASSED=0" >> $GITHUB_ENV
        fi
        
        if [ -z "$COVERAGE_PCT" ]; then
          echo "COVERAGE_PCT=0" >> $GITHUB_ENV
        fi
        
        # Determine colors based on test results
        UNIT_COLOR=$([ "$UNIT_PASSED" -eq "$UNIT_TOTAL" ] && echo "success" || echo "critical")
        INTEGRATION_COLOR=$([ "$INTEGRATION_PASSED" -eq "$INTEGRATION_TOTAL" ] && echo "success" || echo "critical")
        COVERAGE_COLOR=$([ ${{ env.COVERAGE_PCT }} -ge 80 ] && echo "success" || ([ ${{ env.COVERAGE_PCT }} -ge 60 ] && echo "yellow" || echo "critical"))
        
        # Create badge for unit tests
        cat > test-results/python/badge-unit.json << EOF
        {
          "schemaVersion": 1,
          "label": "Unit",
          "message": "${UNIT_PASSED}/${UNIT_TOTAL}",
          "color": "${UNIT_COLOR}"
        }
        EOF
        
        # Create badge for integration tests
        cat > test-results/python/badge-integration.json << EOF
        {
          "schemaVersion": 1,
          "label": "Integration",
          "message": "${INTEGRATION_PASSED}/${INTEGRATION_TOTAL}",
          "color": "${INTEGRATION_COLOR}"
        }
        EOF
        
        # Create badge for coverage only
        cat > test-results/python/badge-coverage.json << EOF
        {
          "schemaVersion": 1,
          "label": "Coverage",
          "message": "${{ env.COVERAGE_PCT }}%",
          "color": "${COVERAGE_COLOR}"
        }
        EOF
        
        ls -la test-results/python
    
    - name: Deploy test results to test-results branch
      if: always() && github.ref == 'refs/heads/main'
      uses: JamesIves/github-pages-deploy-action@v4
      with:
        folder: test-results
        target-folder: test-results
        branch: test-results
        clean: false
    
    - name: Upload test coverage as artifact
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: python-coverage
        path: test-results/python/coverage/
        retention-days: 30